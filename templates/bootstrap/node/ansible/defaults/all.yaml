---
all:
  children:
    kiss_ephemeral_node:
      vars: {}
    kube_control_plane:
    kube_node:
    calico_rr:
      hosts: {}
    etcd:
    k8s_cluster_default:
      vars: {}
    k8s_cluster:
      children:
        kube_control_plane:
        kube_node:
      vars:
        #############################
        # k8s-cluster
        #############################

        # Kubernetes configuration dirs and system namespace.
        # Those are where all the additional config stuff goes
        # the kubernetes normally puts in /srv/kubernetes.
        # This puts them in a sane location and namespace.
        # Editing those values will almost surely break something.
        kube_config_dir: /etc/kubernetes

        ### fail with swap on (default true)
        kubelet_fail_swap_on: true

        # An alternative flexvolume plugin directory
        kubelet_flexvolumes_plugins_dir: /var/lib/kubelet/volumeplugins

        ## Container runtime
        ## docker for docker, crio for cri-o and containerd for containerd.
        ## Additionally you can set this to kubeadm if you want to install etcd using kubeadm
        ## Kubeadm etcd deployment is experimental and only available for new deployments
        ## If this is not set, container manager will be inherited from the Kubespray defaults
        ## and not from k8s_cluster/k8s-cluster.yml, which might not be what you want.
        ## Also this makes possible to use different container manager for etcd nodes.
        container_manager: containerd

        containerd_base_runtime_spec_rlimit_nofile: 524288

        # Containerd conf default dir
        containerd_storage_dir: "/var/lib/containerd"

        ## An obvious use case is allowing insecure-registry access to self hosted registries.
        ## Can be ipaddress and domain_name.
        ## example define mirror.registry.io or 172.19.16.11:5000
        ## set "name": "url". insecure url must be started http://
        ## Port number is also needed if the default HTTPS port is not used.
        containerd_insecure_registries:
          "ark-registry.ark.svc.ops.openark": "http://registry.ark.svc.ops.openark"

        ## Settings for etcd deployment type
        # Set this to docker if you are using container_manager: docker
        etcd_deployment_type: "{{ 'docker' if container_manager == 'docker' else 'host' }}" # data is stored in /opt/etcd
        # Directory where etcd data stored
        etcd_data_dir: /opt/etcd
        etcd_config_dir: /etc/etcd
        etcd_events_data_dir: /var/lib/etcd-events

        # Choose network plugin (cilium, calico, kube-ovn, weave or flannel. Use cni for generic cni plugin)
        # Can also be set to 'cloud', which lets the cloud provider setup appropriate routing
        kube_network_plugin: calico

        ## Settings for calico CNI
        # add default ippool blockSize (defaults kube_network_node_prefix)
        calico_pool_blocksize: 26
        # Global as_num (/calico/bgp/v1/global/as_num)
        global_as_num: "64512"
        # You can set MTU value here. If left undefined or empty, it will
        # not be specified in calico CNI config, so Calico will use built-in
        # defaults. The value should be a number, not a string.
        calico_mtu: 9000
        # Choose data store type for calico: "etcd" or "kdd" (kubernetes datastore)
        # The default value for calico_datastore is set in role kubespray-default
        calico_datastore: kdd
        # Calico container settings
        calico_allow_ip_forwarding: false
        # Should calico ignore kernel's RPF check setting,
        # see https://github.com/projectcalico/felix/blob/ab8799eaea66627e5db7717e62fca61fd9c08646/python/calico/felix/config.py#L198
        calico_node_ignorelooserpf: false
        # Advertise Cluster IPs
        calico_advertise_cluster_ips: true
        # Advertise Service LoadBalancer IPs
        calico_advertise_service_loadbalancer_ips:
          - 192.168.0.0/24 # Dev
        # Configure peering with router(s) at global scope
        peer_with_router: false
        # Set calico network backend: "bird", "vxlan" or "none"
        # bird enable BGP routing, required for ipip and no encapsulation modes
        calico_network_backend: bird # enable BGP routing
        # Enable BGP encapsulation mode
        calico_ipip_mode: Never
        calico_vxlan_mode: Never
        # Enable eBPF mode
        calico_bpf_enabled: false

        # Setting multi_networking to true will install Multus: https://github.com/intel/multus-cni
        kube_network_plugin_multus: false

        # internal network. When used, it will assign IP
        # addresses from this range to individual pods.
        # This network must be unused in your network infrastructure!
        kube_pods_subnet: 10.48.0.0/12
        kube_child_pods_subnet: 10.96.0.0/12

        # internal network node size allocation (optional). This is the size allocated
        # to each node for pod IP address allocation. Note that the number of pods per node is
        # also limited by the kubelet_max_pods variable which defaults to 110.
        #
        # Example:
        # Up to 64 nodes and up to 254 or kubelet_max_pods (the lowest of the two) pods per node:
        #  - kube_pods_subnet: 10.233.64.0/18
        #  - kube_network_node_prefix: 24
        #  - kubelet_max_pods: 110
        #
        # Example:
        # Up to 128 nodes and up to 126 or kubelet_max_pods (the lowest of the two) pods per node:
        #  - kube_pods_subnet: 10.233.64.0/18
        #  - kube_network_node_prefix: 25
        #  - kubelet_max_pods: 110
        kube_network_node_prefix: 26

        # Kubernetes internal network for services, unused block of space.
        kube_service_addresses: 10.64.0.0/12 # same as calico CIDR
        kube_child_service_addresses: 10.112.0.0/12 # same as calico CIDR

        ## Kube Proxy mode One of ['iptables','ipvs']
        kube_proxy_mode: ipvs

        # Configure Dual Stack networking (i.e. both IPv4 and IPv6)
        enable_dual_stack_networks: false # disable IPv6

        # configure arp_ignore and arp_announce to avoid answering ARP queries from kube-ipvs0 interface
        # must be set to true for MetalLB to work
        kube_proxy_strict_arp: true # set to true for MetalLB to work

        # DNS configuration.
        # Kubernetes cluster name, also will be used as DNS domain
        cluster_name: ops.openark # append `ops.` to prevent `openark.` from begin TLD

        ## Upstream dns servers
        upstream_dns_servers:
          - 1.1.1.1
          - 8.8.8.8

        # Enable nodelocal dns cache
        enable_nodelocaldns: true

        # Enable k8s_external plugin for CoreDNS
        enable_coredns_k8s_external: true
        coredns_k8s_external_zone: k8s.openark # Inter-cluster External DNS
        # Enable endpoint_pod_names option for kubernetes plugin
        enable_coredns_k8s_endpoint_pod_names: false

        # nginx-proxy configure
        nginx_config_dir: /etc/nginx

        # krew root dir
        krew_root_dir: /usr/local/krew

        # sysctl_file_path to add sysctl conf to
        sysctl_file_path: /etc/sysctl.d/99-sysctl.conf

        #############################
        # addons
        #############################

        # Kubernetes dashboard
        # RBAC required. see docs/getting-started.md for access details.
        dashboard_enabled: true

        # Helm deployment
        helm_enabled: true

        # Metrics Server deployment
        metrics_server_enabled: true

        # Local volume provisioner deployment
        local_volume_provisioner_enabled: false
        # local_volume_provisioner_storage_classes:
        #   local-storage:
        #     host_dir: /mnt/disks
        #     mount_dir: /mnt/disks
        #     volume_mode: Filesystem
        #     fs_type: ext4
        #   fast-disks:
        #     host_dir: /mnt/fast-disks
        #     mount_dir: /mnt/fast-disks
        #     block_cleaner_command:
        #       - "/scripts/shred.sh"
        #       - "2"
        #     volume_mode: Filesystem
        #     fs_type: ext4

        # Cert manager deployment
        cert_manager_enabled: true
        cert_manager_namespace: cert-manager

        # MetalLB deployment
        metallb_enabled: true
        metallb_speaker_enabled: false
        metallb_config:
          address_pools:
            dev:
              ip_range:
                - 192.168.0.0/24 # for Development
              auto_assign: true
              avoid_buggy_ips: true
          layer3:
            defaults:
              peer_port: 179 # The TCP port to talk to. Defaults to 179, you shouldn't need to set this in production.
              hold_time: 120s # Requested BGP hold time, per RFC4271.
            # borrow calico BGP peers
            metallb_peers: {}

        #############################
        # Hardening
        #############################

        ## kube-apiserver
        authorization_modes:
          - Node
          - RBAC
        # AppArmor-based OS
        # kube_apiserver_feature_gates: ['AppArmor=true']
        kube_apiserver_request_timeout: 120s
        kube_apiserver_service_account_lookup: true

        # enable kubernetes audit
        kubernetes_audit: true
        audit_log_path: /var/log/kube-apiserver-log.json
        audit_log_maxage: 30
        audit_log_maxbackups: 10
        audit_log_maxsize: 100

        tls_min_version: VersionTLS12
        tls_cipher_suites:
          - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
          - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
          - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305

        # enable encryption at rest
        kube_encrypt_secret_data: true
        kube_encryption_resources:
          - secrets
        kube_encryption_algorithm: secretbox

        kube_apiserver_enable_admission_plugins:
          - EventRateLimit
          - AlwaysPullImages
          - ServiceAccount
          - NamespaceLifecycle
          - NodeRestriction
          - LimitRanger
          - ResourceQuota
          - MutatingAdmissionWebhook
          - ValidatingAdmissionWebhook
          - PodNodeSelector
          - PodSecurity
        kube_apiserver_admission_control_config_file: true
        # EventRateLimit plugin configuration
        kube_apiserver_admission_event_rate_limits:
          limit_1:
            type: Namespace
            qps: 50
            burst: 100
            cache_size: 2000
          limit_2:
            type: User
            qps: 50
            burst: 100
        kube_profiling: false

        ## kube-controller-manager
        kube_controller_manager_bind_address: 127.0.0.1
        kube_controller_terminated_pod_gc_threshold: 50
        # AppArmor-based OS
        # kube_controller_feature_gates: ["RotateKubeletServerCertificate=true", "AppArmor=true"]
        kube_controller_feature_gates:
          - RotateKubeletServerCertificate=true

        ## kube-scheduler
        kube_scheduler_bind_address: 127.0.0.1
        # AppArmor-based OS
        # kube_scheduler_feature_gates: ["AppArmor=true"]

        ## kubelet
        kubelet_authorization_mode_webhook: true
        kubelet_authentication_token_webhook: true
        kube_read_only_port: 0
        kubelet_rotate_server_certificates: true
        kubelet_protect_kernel_defaults: true
        kubelet_event_record_qps: 1
        kubelet_rotate_certificates: true
        kubelet_streaming_connection_idle_timeout: 5m
        kubelet_make_iptables_util_chains: true
        kubelet_feature_gates:
          - RotateKubeletServerCertificate=true
          - SeccompDefault=true
        kubelet_seccomp_default: true
        kubelet_systemd_hardening: false
        # In case you have multiple interfaces in your
        # control plane nodes and you want to specify the right
        # IP addresses, kubelet_secure_addresses allows you
        # to specify the IP from which the kubelet
        # will receive the packets.
        # kubelet_secure_addresses: 192.168.10.110 192.168.10.111 192.168.10.112

        # additional configurations
        kube_owner: root
        kube_cert_group: root

        # create a default Pod Security Configuration and deny running of insecure pods
        # kube_system namespace is exempted by default
        kube_pod_security_use_default: true
        kube_pod_security_default_enforce: restricted
