---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: "desktop-{{ spec.node.metadata.name }}"
  namespace: "{{ namespace }}"
spec:
  selector:
    matchLabels:
      name: desktop
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        name: desktop
    spec:
      nodeName: "{{ spec.node.metadata.name }}"
      affinity:
        nodeAffinity:
          # KISS ephemeral control plane nodes should be excluded
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node-role.kubernetes.io/kiss
                    operator: In
                    values:
                      - Desktop
              - matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: In
                    values:
                      - "{{ spec.node.metadata.name }}"
      containers:
        - name: desktop-environment
          image: quay.io/ulagbulag-village/netai-cloud-vdi-desktop:latest
          imagePullPolicy: Always
          command:
            - /opt/scripts/entrypoint-desktop.sh
          env:
            - name: DISPLAY
              value: ":0"
            - name: HOME
              value: /home/user
            - name: KISS_DESKTOP_FONTS_URL
              value: ""
            - name: KISS_DESKTOP_ICONS_URL
              value: ""
            - name: KISS_DESKTOP_THEMES_URL
              value: ""
            - name: KISS_DESKTOP_TEMPLATE_GIT
              value: https://github.com/ulagbulag-village/netai-cloud-desktop-template.git
            - name: KISS_DESKTOP_TEMPLATE_GIT_BRANCH
              value: master
            - name: LANG
              value: ko_KR.UTF-8
            - name: LC_ALL
              value: ko_KR.UTF-8
            - name: LOCALE
              value: ko_KR.UTF-8
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: all
            - name: NVIDIA_VISIBLE_DEVICES
              value: all
            - name: USER
              value: "2000"
            - name: WINEVERSION
              value: "7.22"
            - name: XDG_RUNTIME_DIR
              value: /run/user/2000
          securityContext:
            capabilities:
              add:
                - apparmor:unconfined
            privileged: true
          workingDir: /home/user
          volumeMounts:
            - name: dev
              mountPath: /dev
            - name: dev-dri
              mountPath: /dev/dri
            - name: dev-fuse
              mountPath: /dev/fuse
            - name: egl-icd-loader
              mountPath: /etc/glvnd/egl_vendor.d
              readOnly: true
            - name: home
              mountPath: /home/user
            - name: machine-id
              mountPath: /etc/machine-id
              readOnly: true
            - name: ice
              mountPath: /tmp/.ICE-unix
            - name: runtime-dbus
              mountPath: /run/dbus
            - name: runtime-user
              mountPath: /run/user/2000
            - name: tmp
              mountPath: /tmp
            - name: vine
              mountPath: /tmp/.vine
            - name: vine-lock
              mountPath: /tmp/.vine/.login.lock
            - name: vulkan-icd-loader
              mountPath: /etc/vulkan/icd.d
              readOnly: true
            - name: x11
              mountPath: /tmp/.X11-unix
          {% if spec.boxQuota.compute is object %}
          resources: {{ spec.boxQuota.compute | json_encode() | safe }}
          {% endif %}
      hostIPC: true
      securityContext:
        runAsNonRoot: false
        runAsUser: 2000
        fsGroup: 2000
      terminationGracePeriodSeconds: 1
      volumes:
        - name: dev
          hostPath:
            path: /dev
            type: Directory
        - name: dev-dri
          hostPath:
            path: /dev/dri
            type: Directory
        - name: dev-fuse
          hostPath:
            path: /dev/fuse
            type: CharDevice
        - name: egl-icd-loader
          hostPath:
            path: /usr/share/glvnd/egl_vendor.d
            type: Directory
        - name: home
          persistentVolumeClaim:
            claimName: "desktop-{{ spec.node.metadata.name }}"
        - name: machine-id
          hostPath:
            path: /etc/machine-id
            type: File
        - name: ice
          hostPath:
            path: /tmp/.ICE-unix
            type: Directory
        - name: runtime-dbus
          hostPath:
            path: /run/dbus
            type: Directory
        - name: runtime-user
          hostPath:
            path: /run/user/2000
            type: Directory
        - name: tmp
          emptyDir: {}
        - name: vine
          hostPath:
            path: /tmp/.vine
            type: DirectoryOrCreate
        - name: vine-lock
          emptyDir: {}
        - name: vulkan-icd-loader
          hostPath:
            path: /usr/share/vulkan/icd.d
            type: Directory
        - name: x11
          hostPath:
            path: /tmp/.X11-unix
            type: Directory
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: triton
  namespace: "{{ namespace }}"
spec:
  selector:
    matchLabels:
      name: triton
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        name: triton
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node-role.kubernetes.io/kiss
                    operator: In
                    values:
                      - Compute
      initContainers:
        - name: fetch-models
          image: nvcr.io/nvidia/triton:23.02-py3
          command:
            - bash
            - -c
          args:
            - >
              git clone -b r23.02 "https://github.com/triton-inference-server/server.git"
              && cd server/docs/examples
              && ./fetch_models.sh
              && mv model_repository/* /models/
          volumeMounts:
            - name: models
              mountPath: /models
      containers:
        - name: triton-inference-server
          image: nvcr.io/nvidia/triton:23.02-py3
          command:
            - triton
          args:
            - --model-repository=/models
          ports:
            - name: http
              protocol: TCP
              containerPort: 8000
            - name: grpc
              protocol: TCP
              containerPort: 8001
            - name: metrics
              protocol: TCP
              containerPort: 8002
          resources:
            limits:
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: models
              mountPath: /models
      volumes:
        - name: models
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: triton
  namespace: "{{ namespace }}"
spec:
  selector:
    name: triton
  ports:
    - name: http
      port: 8000
      protocol: TCP
      targetPort: 8000
    - name: grpc
      port: 8001
      protocol: TCP
      targetPort: 8001
    - name: metrics
      port: 8002
      protocol: TCP
      targetPort: 8002
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: "desktop-{{ spec.node.metadata.name }}"
  namespace: "{{ namespace }}"
spec:
  accessModes:
    - ReadWriteMany
  {% if spec.boxQuota.storage is object %}
  resources: {{ spec.boxQuota.storage | json_encode() | safe }}
  {% endif %}
  {% if spec.boxQuota.storageClassName is string %}
  storageClassName: "{{ spec.boxQuota.storageClassName }}"
  {% endif %}
