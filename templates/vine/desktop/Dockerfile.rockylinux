# Copyright (c) 2023 Ho Kim (ho.kim@ulagbulag.io). All rights reserved.
# Use of this source code is governed by a GPL-3-style license that can be
# found in the LICENSE file.

# Configure environment variables
ARG ROCKYLINUX_VERSION="8"

# Configure user-specific environment variables
ARG USER_GID="2000"
ARG USER_NAME="user"
ARG USER_SHELL="zsh"
ARG USER_SUDO="true"
ARG USER_UID="2000"

# Be ready for serving
FROM "quay.io/rockylinux/rockylinux:${ROCKYLINUX_VERSION}"

# Load user-specific environment variables
ARG USER_GID
ARG USER_NAME
ARG USER_SHELL
ARG USER_SUDO
ARG USER_UID

# SystemD Configuration
ENV container docker
STOPSIGNAL SIGRTMIN+3

# Client Configuration
WORKDIR /root/
ENTRYPOINT [ "/usr/bin/env" ]
CMD [ "/usr/bin/firefox" ]

# Volumes Configuration
## home.user
VOLUME [ "/home/${USER_NAME}" ]

# Update locale
RUN echo 'override_install_langs=en_US' >>/etc/yum.conf

# Add core repositories
ADD ./yum/yum.repos.d/*.repo /etc/yum.repos.d/
RUN dnf install -y \
    epel-release \
    "https://mirrors.rpmfusion.org/free/el/rpmfusion-free-release-$(rpm -E %rhel).noarch.rpm" \
    "https://pkgs.dyn.su/el$(rpm -E %rhel)/base/x86_64/raven-release.el$(rpm -E %rhel).noarch.rpm" \
    && dnf config-manager --set-enabled powertools \
    && dnf config-manager --set-disabled raven raven-extras raven-modular raven-multimedia raven-testing \
    && curl "https://nvidia.github.io/nvidia-docker/centos$(rpm -E %rhel)/nvidia-docker.repo" > /etc/yum.repos.d/nvidia-docker.repo \
    # Cleanup
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install core dependencies
RUN dnf install -y \
    libglvnd-gles \
    mesa-dri-drivers \
    pipewire \
    vulkan \
    #wireplumber \
    wmctrl \
    xdotool \
    xprop \
    yum-utils \
    # Cleanup
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install locale dependencies
RUN dnf install -y \
    glibc-langpack-ko \
    # Cleanup
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install AI dev core dependencies
ARG DEEPSTREAM_DOCKERFILE_URL="https://raw.githubusercontent.com/NVIDIA-AI-IOT/deepstream_dockers/main/x86_64/Makefile_x86_triton"
ARG DEEPSTREAM_VERSION_URL="https://raw.githubusercontent.com/NVIDIA-AI-IOT/deepstream_dockers/main/common/version"
RUN yum check-update -y \
    ; CUDA_VERSION="$( \
    curl -s "${DEEPSTREAM_DOCKERFILE_URL}" \
    | grep -Po 'TENSORRT_VERSION\=\"[0-9\.\-]+\+cuda\K[0-9\.]+' \
    | sed 's/\./\-/g' \
    )" \
    && dnf install -y --enablerepo rpmfusion-free-updates \
    "cuda-cudart-devel-${CUDA_VERSION}" \
    "$(dnf list 'cuda-cufft-[0-9-]*' -q | grep -Po 'cuda-cufft-[0-9-]*' | tail -n 1)" \
    glib2-devel \
    gstreamer1-devel \
    gstreamer1-libav \
    gstreamer1-plugins-bad-free \
    gstreamer1-plugins-base-devel \
    gstreamer1-plugins-good \
    gstreamer1-plugins-ugly \
    gstreamer1-plugins-ugly-free \
    gstreamer1-svt-av1 \
    json-glib \
    "libcublas-devel-${CUDA_VERSION}" \
    "$(dnf list 'libcublas-devel-[0-9-]*' -q | grep -Po 'libcublas-devel-[0-9-]*' | tail -n 1)" \
    "libnpp-devel-${CUDA_VERSION}" \
    libuuid \
    opencv \
    openssl \
    tensorrt \
    yaml-cpp \
    # Environment Variables Configuration
    && echo '# NVIDIA CUDA binary path registration' >/etc/profile.d/path-nvidia-cuda-bin.sh \
    && echo '# NVIDIA CUDA library path registration' >/etc/ld.so.conf.d/900-nvidia-cuda.conf \
    && for cuda_home in /usr/local/cuda\-[0-9]*.[0-9]*; do true \
    && echo "export PATH=\${PATH}:${cuda_home}/bin" >>/etc/profile.d/path-nvidia-cuda-bin.sh \
    && echo "${cuda_home}/lib" >>/etc/ld.so.conf.d/900-nvidia-cuda.conf \
    && echo "${cuda_home}/lib64" >>/etc/ld.so.conf.d/900-nvidia-cuda.conf \
    ; done \
    && ldconfig \
    # Cleanup
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install development environment dependencies
RUN rpm --setcaps shadow-utils 2>/dev/null \
    && dnf install -y --enablerepo kubernetes \
    "@Development Tools" \
    crun \
    fuse-overlayfs \
    git \
    kubectl \
    nano \
    nvidia-container-toolkit-base \
    openssh-clients \
    pciutils \
    podman-docker \
    python3 \
    python3-pip \
    sudo \
    "${USER_SHELL}" \
    vim \
    wget \
    zip \
    --exclude container-selinux \
    # Allow passwordless sudo command
    && if [ "x${USER_SUDO}" == "xtrue" ]; then \
    echo "${USER_NAME} ALL=(ALL) NOPASSWD: ALL" >/etc/sudoers.d/10-wheel \
    && chmod 440 /etc/sudoers.d/10-wheel \
    ; fi \
    # Docker (Podman) Configuration
    && systemctl enable podman \
    && touch /etc/containers/nodocker \
    ## chmod containers.conf and adjust storage.conf to enable Fuse storage.
    && sed -i \
    -e 's|^#mount_program|mount_program|g' \
    -e '/additionalimage.*/a "/var/lib/shared",' \
    -e 's|^mountopt[[:space:]]*=.*$|mountopt = "nodev,fsync=0"|g' \
    /etc/containers/storage.conf \
    && mkdir -p \
    /var/lib/shared/overlay-images \
    /var/lib/shared/overlay-layers \
    /var/lib/shared/vfs-images \
    /var/lib/shared/vfs-layers \
    && touch /var/lib/shared/overlay-images/images.lock \
    && touch /var/lib/shared/overlay-layers/layers.lock \
    && touch /var/lib/shared/vfs-images/images.lock \
    && touch /var/lib/shared/vfs-layers/layers.lock \
    ## generate a CDI specification that refers to all NVIDIA devices
    && mkdir -p /etc/cdi/ \
    && chown -R "${USER_UID}:${USER_GID}" /etc/cdi/ \
    # Environment Variables Configuration
    && echo '# local binary path registration' >/etc/profile.d/path-local-bin.sh \
    && echo 'export PATH=${PATH}:/usr/local/bin' >>/etc/profile.d/path-local-bin.sh \
    && echo 'export PATH=${PATH}:/opt/bin' >>/etc/profile.d/path-local-bin.sh \
    && ln -sf /usr/local/bin /opt/bin \
    && echo '# local library path registration' >/etc/ld.so.conf.d/100-path-local-lib.conf \
    && echo '/usr/local/lib' >>/etc/ld.so.conf.d/100-path-local-lib.conf \
    && echo '/usr/local/lib64' >>/etc/ld.so.conf.d/100-path-local-lib.conf \
    && ldconfig \
    # Cleanup
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install desktop environment dependencies
RUN dnf install -y --enablerepo raven \
    bluez \
    code \
    dbus-x11 \
    file-roller \
    gnome-bluetooth \
    ibus-hangul \
    NetworkManager-bluetooth \
    NetworkManager-tui \
    NetworkManager-wifi \
    network-manager-applet \
    nm-connection-editor \
    openssh-askpass \
    picom \
    plank \
    sqlite \
    Thunar thunar-archive-plugin thunar-volman \
    tumbler \
    xdg-dbus-proxy \
    xfce4-appfinder xfce4-notifyd xfce4-panel xfce4-pulseaudio-plugin \
    xfce4-session xfce4-settings xfce4-terminal \
    xfconf xfdesktop xfwm4 \
    xmlstarlet \
    # Disable xfce-polkit
    && rm /etc/xdg/autostart/xfce-polkit.desktop \
    && rm /usr/libexec/xfce-polkit \
    # Cleanup
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install blueman dependencies
ARG BLUEMAN_REPO="https://github.com/blueman-project/blueman/releases/download"
ARG BLUEMAN_VERSION="2.2.1"
RUN dnf install -y \
    bluez-libs-devel \
    iproute \
    pygobject3-devel \
    python3-Cython \
    python3-devel \
    # Download
    && BLUEMAN_SRC_FILENAME="blueman-${BLUEMAN_VERSION}.tar.xz" \
    && BLUEMAN_SRC_FILE="/opt/${BLUEMAN_SRC_FILENAME}.tar.xz" \
    && BLUEMAN_SRC_HOME="/opt/${BLUEMAN_SRC_FILENAME%.tar.xz}" \
    && wget -O "${BLUEMAN_SRC_FILE}" "${BLUEMAN_REPO}/${BLUEMAN_VERSION}/${BLUEMAN_SRC_FILENAME}" \
    # Decompress the downloaded file
    && tar -x -C "$(dirname "${BLUEMAN_SRC_HOME}")" -f "${BLUEMAN_SRC_FILE}" \
    # Build
    && pushd "${BLUEMAN_SRC_HOME}" \
    && ./configure && make && make install \
    && popd \
    # Cleanup
    && rm -rf "${BLUEMAN_SRC_FILE}" "${BLUEMAN_SRC_HOME}" \
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install internet browsers
RUN dnf install -y \
    firefox \
    google-chrome-stable \
    # Cleanup
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install AI dev build dependencies - Force update glibc & libstdc++
RUN BIN_DIR="/opt/tmp-updates" \
    && mkdir -p "${BIN_DIR}" \
    && pushd "${BIN_DIR}" \
    # Download
    && dnf download --quiet --arch "$(uname -m)" --releasever 9 --repo baseos \
    glibc \
    libstdc++ \
    # Decompress the downloaded files
    && for file in *.rpm; do true \
    && rpm2cpio "${file}" | cpio -idmv -D "/" \
    ; done \
    && ldconfig \
    # Cleanup
    && popd \
    && rm -rf "${BIN_DIR}" \
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install AI dev build dependencies - `gst-rtsp-server-devel`
ARG GST_RTSP_SERVER_FILENAME="gst-rtsp-server-1.14.5.tar.xz"
ARG GST_RTSP_SERVER_REPO="https://gstreamer.freedesktop.org/src/gst-rtsp-server"
RUN true \
    ## Get the latest version
    #&& GST_RTSP_SERVER_FILENAME=$( \
    #curl -s "${GST_RTSP_SERVER_REPO}/" \
    #| grep -Po 'a href="\Kgst-rtsp-server-[0-9.]+.tar.xz' \
    #| tail -n 1 \
    #) \
    # Download
    && GST_RTSP_SERVER_SRC_FILE="/opt/gst-rtsp-server.tar.xz" \
    && GST_RTSP_SERVER_SRC_HOME="/opt/${GST_RTSP_SERVER_FILENAME%.tar.xz}" \
    && wget -O "${GST_RTSP_SERVER_SRC_FILE}" "${GST_RTSP_SERVER_REPO}/${GST_RTSP_SERVER_FILENAME}" \
    # Decompress the downloaded file
    && tar -x -C "$(dirname "${GST_RTSP_SERVER_SRC_HOME}")" -f "${GST_RTSP_SERVER_SRC_FILE}" \
    # Build
    && pushd "${GST_RTSP_SERVER_SRC_HOME}" \
    && ./configure && make && make install \
    && popd \
    # Cleanup
    && rm -rf "${GST_RTSP_SERVER_SRC_FILE}" "${GST_RTSP_SERVER_SRC_HOME}"

# Install AI dev dependencies
ARG DEEPSTREAM_REFERENCES_REPO_URL="https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps.git"
ARG DEEPSTREAM_URL_DOWNLOAD="https://developer.download.nvidia.com/assets/Deepstream"
RUN true \
    # Get the latest version
    && DEEPSTREAM_VERSION=$( \
    curl -s "${DEEPSTREAM_VERSION_URL}" \
    | grep -Po '^version\=\K[0-9\.]+$' \
    ) \
    # Parse the version information
    && DEEPSTREAM_HOME="/opt/nvidia/deepstream/deepstream" \
    && DEEPSTREAM_VERSION_MAJOR="$(echo "${DEEPSTREAM_VERSION}" | awk -F '.' '{print $1}')" \
    && DEEPSTREAM_VERSION_MINOR="$(echo "${DEEPSTREAM_VERSION}" | awk -F '.' '{print $2}')" \
    && DEEPSTREAM_VERSION_PATCH="$(echo "${DEEPSTREAM_VERSION}" | awk -F '.' '{print $3}')" \
    && DEEPSTREAM_VERSION_RELEASE="${DEEPSTREAM_VERSION_MAJOR}.${DEEPSTREAM_VERSION_MINOR}" \
    && DEEPSTREAM_VERSION_FULL="${DEEPSTREAM_VERSION_RELEASE}.${DEEPSTREAM_VERSION_PATCH}" \
    # Download
    && DEEPSTREAM_SDK_FILE="/opt/deepstream-sdk.tbz2" \
    && wget -O "${DEEPSTREAM_SDK_FILE}" "${DEEPSTREAM_URL_DOWNLOAD}/DeepStream_${DEEPSTREAM_VERSION_RELEASE}/deepstream_sdk_v${DEEPSTREAM_VERSION_FULL}_$(uname -m).tbz2" \
    # Decompress the downloaded file
    && tar -x -C '/' -f "${DEEPSTREAM_SDK_FILE}" \
    # Install
    && pushd "${DEEPSTREAM_HOME}" \
    && sed -i 's/"rhel"/"rocky"/g' ./*.sh \
    && ./install.sh && ldconfig \
    && rm -f *.sh \
    && popd \
    # Download the latest configuration files
    && DEEPSTREAM_MODELS_DIR="${DEEPSTREAM_HOME}/samples/configs/tao_pretrained_models" \
    && DEEPSTREAM_SAMPLE_HOME="/opt/deepstream_reference_apps" \
    && git clone "${DEEPSTREAM_REFERENCES_REPO_URL}" "${DEEPSTREAM_SAMPLE_HOME}" \
    && pushd "${DEEPSTREAM_SAMPLE_HOME}/deepstream_app_tao_configs/" \
    && cp -a * "${DEEPSTREAM_MODELS_DIR}" \
    && popd \
    # Download the models
    && pushd "${DEEPSTREAM_MODELS_DIR}" \
    && ./download_models.sh \
    && popd \
    # Change permissions for user-level modification
    && chown -R "${USER_UID}:${USER_GID}" "${DEEPSTREAM_HOME}/samples" \
    # Cleanup
    && rm -rf "${DEEPSTREAM_SAMPLE_HOME}" \
    && rm -f "${DEEPSTREAM_SDK_FILE}"

# Install utility
RUN ARCH_WIN32='i686' \
    && dnf install -y \
    # Games (Lutris)
    "gnutls.${ARCH_WIN32}" \
    "mesa-dri-drivers.${ARCH_WIN32}" \
    "mesa-libEGL.${ARCH_WIN32}" \
    "mesa-libGLU.${ARCH_WIN32}" \
    python3-certifi \
    python3-distro \
    python3-gobject \
    python3-lxml \
    python3-pillow \
    python3-pyyaml \
    python3-requests \
    "vulkan-loader.${ARCH_WIN32}" \
    webkit2gtk3 \
    wine \
    winetricks \
    # Cleanup
    && dnf clean all \
    && rm -rf /var/cache /var/log/dnf* /var/log/yum.*

# Install utility - WINE staging
ARG WINE_REPO="https://github.com/Kron4ek/Wine-Builds/releases/download"
RUN true \
    # Get the latest version
    ## ARCH
    && case "$(uname -m)" in \
    'i386') \
    WINE_ARCH='x86' \
    ;; \
    'x86_64') \
    WINE_ARCH='amd64' \
    ;; \
    *) \
    echo "Unsupported WINE Architechure: '$(uname -m)'" \
    exit 1 \
    ;; \
    esac \
    && WINE_VERSION="8.1" \
    # Download
    && WINE_OBJ_NAME="wine-${WINE_VERSION}-staging-tkg-${WINE_ARCH}" \
    && WINE_OBJ_FILENAME="${WINE_OBJ_NAME}.tar.xz" \
    && WINE_OBJ_FILE="${WINE_OBJ_FILENAME}" \
    && WINE_TMP="/opt/${WINE_OBJ_NAME}" \
    && wget -O "${WINE_OBJ_FILE}" "${WINE_REPO}/${WINE_VERSION}/${WINE_OBJ_FILENAME}" \
    # Decompress the downloaded file
    && tar -x -C "$(dirname "${WINE_TMP}")" -f "${WINE_OBJ_FILE}" \
    && tar -cf - -C "${WINE_TMP}" . | tar -xf - -C '/usr' \
    # Cleanup
    && rm -rf "${WINE_OBJ_FILE}" "${WINE_TMP}"

# Install utilities - Games - Lutris
ARG LUTRIS_REPO="https://lutris.net/releases"
RUN true \
    # Get the latest version
    && LUTRIS_VERSION=$( \
    curl -s "${LUTRIS_REPO}/" \
    | grep -Po 'lutris\_[0-9\.]+\.tar\.xz' \
    | sort -V \
    | tail -n 1 \
    ) \
    # Download
    && LUTRIS_HOME="/opt/lutris" \
    && LUTRIS_OBJ_FILE="/opt/lutris.tar.xz" \
    && wget -O "${LUTRIS_OBJ_FILE}" "${LUTRIS_REPO}/${LUTRIS_VERSION}" \
    # Decompress the downloaded file
    && tar -x -C "$(dirname "${LUTRIS_HOME}")" -f "${LUTRIS_OBJ_FILE}" \
    # Environment Variables Configuration
    && echo '# Lutris binary path registration' >/etc/profile.d/path-games-lutris-bin.sh \
    && echo "export PATH=\${PATH}:${LUTRIS_HOME}/bin" >>/etc/profile.d/path-games-lutris-bin.sh \
    && ln -sf /usr/local/bin /opt/bin \
    && echo '# Lutris library path registration' >/etc/ld.so.conf.d/900-path-games-lutris-lib.conf \
    && echo "${LUTRIS_HOME}/lib" >>/etc/ld.so.conf.d/900-path-games-lutris-lib.conf \
    && echo "${LUTRIS_HOME}/lib64" >>/etc/ld.so.conf.d/900-path-games-lutris-lib.conf \
    && ldconfig \
    # Cleanup
    && rm -rf "${LUTRIS_OBJ_FILE}"

# # Install utilities - AI Dev - Training
# RUN python3 -m pip install --no-cache-dir \
#     # PyTorch
#     torch \
#     torchaudio \
#     torchvision \
#     # Cleanup
#     && find / -type d -name '*__pycache__' -prune -exec rm -rf {} \;

# Install utilities - Custom
ARG ADDONS_HOME="/opt/openark/vdi/desktop"
ADD ./addons "${ADDONS_HOME}"
RUN chmod -R a+x "${ADDONS_HOME}/bin" \
    && for file in ${ADDONS_HOME}/share/applications/*.desktop; do true \
    && ln -s "${file}" "/usr/share/applications/$(basename "${file}")" \
    ; done \
    && for file in ${ADDONS_HOME}/share/autostart/*.desktop; do true \
    && ln -s "${file}" "/etc/xdg/autostart/$(basename "${file}")" \
    ; done

# Install utilities - Podman
ARG PODMAN_REPO="https://raw.githubusercontent.com/containers/libpod/master/contrib/podmanimage/stable"
ADD "${PODMAN_REPO}/containers.conf" /etc/containers/containers.conf
ADD "${PODMAN_REPO}/podman-containers.conf" /etc/containers/podman-containers.conf
ENV _CONTAINERS_USERNS_CONFIGURED=""
RUN chmod 644 \
    /etc/containers/containers.conf \
    /etc/containers/podman-containers.conf

# Add firefox preferences
ADD ./browser/firefox/autoconfig.js /usr/lib64/firefox/defaults/pref/
ADD ./browser/firefox/firefox.cfg /usr/lib64/firefox/

# Add read-only shared directory
RUN mkdir -p /opt/public/ \
    && chown -R "${USER_UID}:${USER_GID}" /opt/public/

# Add scripts
ADD ./scripts /opt/scripts/
RUN chmod 0555 /opt/scripts/*

# Add a user
RUN ldconfig \
    && groupadd -g "${USER_GID}" -o "${USER_NAME}" \
    && useradd -u "${USER_UID}" -g "${USER_GID}" -G "audio,cdrom,input,pipewire,render,video" \
    -s "/bin/${USER_SHELL}" -m -o "${USER_NAME}" \
    && echo -e "${USER_UID}:2001:65535" > /etc/subuid \
    && echo -e "${USER_GID}:2001:65535" > /etc/subgid
USER "${USER_NAME}"
WORKDIR "/home/${USER_NAME}"
